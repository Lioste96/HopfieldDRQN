# HopfieldDRQN
This project tests whether Modern Continuous Hopfield Networks can be efficiently embedded in deep reinforcement learning architectures and if it is possible to provide similar results compared to other memory methodologies like LSTM and GRU. The main algorithm used is a Deep Recurrent Q-Network, in which the LSTM layer is replaced with Modern Continuous Hopfield Layers and other types of recurrent layers like GRU to compare the efficiency of the algorithm in a variety of different environments. The architecture of the Deep Recurrent Q-Network is even further adjusted with Convolutional Neural Networks or Fully Connected Layers depending on the dimensionality of the environmentâ€™s observational space.
